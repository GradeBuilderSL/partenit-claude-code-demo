# Partenit Safety Layer — Deterministic Reasoning for Warehouse Robotics

**A trust layer that evaluates robot actions before execution, applies safety policies, and generates structured decision explanations.**

Built with [Claude Code](https://claude.ai/claude-code) as the primary development agent — from architecture design to policy engine implementation and test generation.

---

## What This Project Does

Partenit Safety Layer is a **deterministic reasoning layer** that sits between probabilistic AI perception and physical robot actuators. It ensures that every warehouse robot action passes through a formal policy evaluation before execution.

The system:

- **Evaluates actions in real-time** — every robot command is checked against mathematical safety constraints before it reaches the actuator
- **Makes transparent decisions** — each evaluation produces a structured explanation: ALLOW, MODIFY, or BLOCK, with full reasoning traces
- **Coordinates multi-robot operations** — manages concurrent robot behaviors with collision avoidance, task swapping, and shared resource scheduling
- **Provides natural language control** — operators issue commands in plain English; the safety layer interprets intent and enforces constraints simultaneously

### Interactive Demo

This repository contains a browser-based simulation that demonstrates the full reasoning pipeline. You control two warehouse robots, assign delivery tasks, and observe the safety layer making decisions in real time — including path modifications, proximity alerts, battery management, and constraint-triggered blocks.

**Objective:** Earn $500 in 5 minutes with zero safety violations.

---

## Architecture

```
Operator (natural language command)
        │
        ▼
┌─────────────────────────┐
│   Command Interpreter   │  ← LLM-powered intent parsing
└────────────┬────────────┘
             │
             ▼
┌─────────────────────────┐
│   World State Engine    │  ← Robot positions, battery, worker locations,
│                         │    shelf inventory, active tasks, sensor data
└────────────┬────────────┘
             │
             ▼
┌─────────────────────────┐
│   Policy Evaluation     │  ← Deterministic constraint checks:
│   (Safety Gate)         │    proximity, weight, battery, collision,
│                         │    regulatory (OSHA, ISO)
└────────────┬────────────┘
             │
        ┌────┴────┐
        │         │
     ALLOW     MODIFY / BLOCK
        │         │
        ▼         ▼
┌──────────┐  ┌──────────────────┐
│ Execute  │  │ Adjust or halt   │
│ action   │  │ + explain why    │
└──────────┘  └──────────────────┘
             │
             ▼
┌─────────────────────────┐
│  Explainability Log     │  ← Structured decision record:
│                         │    triggered constraints, risk score,
│                         │    candidate plans, chosen action
└─────────────────────────┘
```

**Key design principle:** The safety gate is purely mathematical — no ML in the critical decision path. LLMs handle language interpretation and explanation generation, but the actual ALLOW/MODIFY/BLOCK decision is deterministic and auditable.

### Tech Stack

| Layer | Technology |
|-------|-----------|
| Frontend | HTML5 Canvas, vanilla JavaScript, CSS3 |
| Backend API | FastAPI (Python), hosted inference |
| Safety Engine | Rule-based constraint evaluator, mathematical proximity/weight/battery models |
| LLM Integration | Gemini or OpenAI (operator's key) for NL command parsing |
| Decision Logging | Structured JSON traces with constraint-level granularity |

---

## How Claude Code Was Used

This project was developed using Claude Code as a coding agent throughout the entire engineering workflow. Below is how Claude contributed at each stage:

### Architecture Design
Claude Code analyzed the requirements for a deterministic safety layer and proposed the separation between probabilistic AI (command interpretation) and deterministic policy evaluation (safety gate). The architecture — world state engine, constraint evaluator, and explainability logger — was designed collaboratively through iterative prompts, with Claude generating system diagrams and data flow specifications.

### Policy Engine Generation
The core policy evaluation logic — proximity constraints, weight limits, battery thresholds, collision detection, multi-robot coordination rules — was generated by Claude Code. Each constraint was formalized as a pure function with defined input/output contracts, enabling independent testing and composition.

### Safety Constraints Formalization
Claude Code helped translate informal safety requirements (OSHA proximity rules, ISO compliance guidelines, vendor weight specifications) into formal constraint definitions with mathematical bounds. Each constraint produces a typed result: `ALLOW`, `MODIFY` (with adjustment parameters), or `BLOCK` (with explanation).

### World State Representation
The world state model — robot positions, velocities, battery levels, worker locations, shelf inventories, active tasks, and sensor readings — was structured by Claude Code to support efficient constraint evaluation. State updates are immutable snapshots, enabling deterministic replay and audit.

### Explainability Layer
Claude Code generated the structured explanation system that logs every safety decision with: triggered constraints, risk scores, candidate action plans, the chosen action, and human-readable reasoning. This layer is critical for regulatory compliance and operator trust.

### Test Generation
Claude Code wrote test cases for constraint evaluation, including edge cases: simultaneous multi-robot proximity violations, battery depletion during active tasks, weight limit boundary conditions, and cascading constraint interactions.

### Iterative Refactoring
Throughout development, Claude Code was used for refactoring passes — improving code organization, extracting shared utilities, tightening type contracts, and simplifying the rendering pipeline. The Canvas-based visualization was iteratively refined through prompt-driven development.

### Development Workflow

```
Prompt (requirement or bug report)
    → Claude Code generates implementation
        → Manual review + test execution
            → Follow-up prompt with feedback
                → Claude Code refines
                    → Commit
```

This workflow was repeated across all components: backend logic, frontend rendering, configuration management, and documentation.

---

## Quick Start

### Prerequisites

You need an LLM API key for natural language command processing:
- **Google Gemini**: [Google AI Studio](https://aistudio.google.com/app/apikey)
- **OpenAI**: [OpenAI Platform](https://platform.openai.com/api-keys)

### Run Locally

```bash
git clone https://github.com/GradeBuilderSL/partenit-claude-code-demo.git
cd partenit-claude-code-demo

# Serve the frontend
python3 -m http.server 8080
# or
npx serve .
```

Open http://localhost:8080, enter your LLM API key, and start a new game.

### Controls

**Chat commands** (per robot):
- `Go charge` — send robot to charging station
- `Pick from shelf 1` — assign pickup task
- `Status` — get robot state
- `Pause` / `Resume` — control operation
- `Drop task T1` — release task to pool

**Strategy configuration:**
- Target robot selector (R1 / R2)
- Speed/Safety slider — trade off throughput vs. caution
- Aggressive mode — allow tighter proximity tolerances
- Auto-assign — let the system distribute tasks

### Decision Transparency

Watch the **Reasoning Engine** panel during gameplay. Every robot action shows:

- **Decision**: ALLOW / MODIFY / BLOCK
- **Triggered constraints**: which safety rules fired
- **Risk score**: quantified risk assessment
- **Candidate plans**: alternative actions considered
- **Explanation**: structured reasoning for the decision

---

## Game Modes

| Mode | Description |
|------|------------|
| Standard Ops | Balanced difficulty, normal worker density |
| Safety Audit | Strict safety enforcement, frequent inspections |
| Battery Crisis | 2x battery drain rate |
| High Throughput | Maximum task density and complexity |

**Difficulty levels:** Easy (1 worker), Medium (3 workers), Chaos (6 workers)

---

## About Partenit

Partenit provides **Robotic Safety Compliance as a Service** — a trust layer ensuring robots operate safely around humans in warehouses, factories, and industrial environments.

Core capabilities:
- Mathematical safety constraints (no AI/ML in the critical decision path)
- Real-time pre-execution evaluation (ALLOW / MODIFY / BLOCK)
- Regulatory compliance (OSHA, ISO, vendor specifications)
- Cryptographic audit trails
- Natural language operator interface

**Website:** [partenit.io](https://partenit.io/)
**LinkedIn:** [linkedin.com/company/partenit](https://www.linkedin.com/company/partenit/)
**Contact:** evgeny.nelepko@partenit.io

---

## License

MIT License — see [LICENSE](LICENSE) for details.

---

**Deterministic reasoning for safer human-robot collaboration.**
